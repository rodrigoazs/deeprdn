{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srlearn.rdn import BoostedRDN\n",
    "from srlearn import Database\n",
    "from srlearn import Background\n",
    "from sklearn.metrics import roc_auc_score, log_loss, precision_recall_curve, auc, precision_score, recall_score\n",
    "import numpy as np\n",
    "from get_datasets import *\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from boost import VectorBoostedRDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cll_score(y_true, y_pred):\n",
    "    def cll(posProb, negProb):\n",
    "        llSum = 0\n",
    "        for prob in posProb:\n",
    "            if prob == 0:\n",
    "                prob = 1e-6\n",
    "            llSum += math.log(prob)\n",
    "        for prob in negProb:\n",
    "            if prob == 1:\n",
    "                prob = 1 - 1e-6\n",
    "            llSum += math.log(1 - prob)\n",
    "        return llSum/(len(posProb) + len(negProb))\n",
    "    posProb = [prob for true, prob in zip(list(y_true), list(y_pred)) if true == 1.0]\n",
    "    negProb = [prob for true, prob in zip(list(y_true), list(y_pred)) if true == 0.0]\n",
    "    return cll(posProb, negProb)\n",
    "\n",
    "def pr_auc_score(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    return auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [\n",
    "    'athleteledsportsteam(+athlete,+sportsteam).',\n",
    "    'athleteledsportsteam(+athlete,-sportsteam).',\n",
    "    'athleteledsportsteam(-athlete,+sportsteam).',\n",
    "    'athleteplaysforteam(+athlete,+sportsteam).',\n",
    "    'athleteplaysforteam(+athlete,-sportsteam).',\n",
    "    'athleteplaysforteam(-athlete,+sportsteam).',\n",
    "    'athleteplaysinleague(+athlete,+sportsleague).',\n",
    "    'athleteplaysinleague(+athlete,-sportsleague).',\n",
    "    'athleteplaysinleague(-athlete,+sportsleague).',\n",
    "    'athleteplayssport(+athlete,+sport).',\n",
    "    'athleteplayssport(+athlete,-sport).',\n",
    "    'athleteplayssport(-athlete,+sport).',\n",
    "    'teamalsoknownas(+sportsteam,+sportsteam).',\n",
    "    'teamalsoknownas(+sportsteam,-sportsteam).',\n",
    "    'teamalsoknownas(-sportsteam,+sportsteam).',\n",
    "    'teamplaysagainstteam(+sportsteam,+sportsteam).',\n",
    "    'teamplaysagainstteam(+sportsteam,-sportsteam).',\n",
    "    'teamplaysagainstteam(-sportsteam,+sportsteam).',\n",
    "    'teamplaysinleague(+sportsteam,+sportsleague).',\n",
    "    'teamplaysinleague(+sportsteam,-sportsleague).',\n",
    "    'teamplaysinleague(-sportsteam,+sportsleague).',\n",
    "    'teamplayssport(+sportsteam,+sport).',\n",
    "    'teamplayssport(+sportsteam,-sport).',\n",
    "    'teamplayssport(-sportsteam,+sport).',\n",
    "]\n",
    "\n",
    "facts, pos, neg = datasets.load('nell_sports', modes, target='teamplayssport')\n",
    "\n",
    "facts, pos, neg = facts[0], pos[0], neg[0]\n",
    "pos, neg = datasets.split_into_folds(pos, 3), datasets.split_into_folds(neg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for fold in range(len(pos)):\n",
    "    results = {}\n",
    "    for _ in range(len(pos)):\n",
    "        test_db = Database()\n",
    "        test_db.pos = pos[fold]\n",
    "        test_db.neg = neg[fold]\n",
    "        test_db.facts = facts\n",
    "\n",
    "        train_db = Database()\n",
    "        train_db.facts = facts\n",
    "        for i in range(len(pos)):\n",
    "            if fold == i:\n",
    "                continue\n",
    "            train_db.pos.extend(pos[i])\n",
    "            train_db.neg.extend(neg[i])\n",
    "\n",
    "        bk = Background(\n",
    "            modes=modes,\n",
    "        )\n",
    "\n",
    "        clf = BoostedRDN(\n",
    "            background=bk,\n",
    "            target=\"teamplayssport\",\n",
    "            n_estimators=10,\n",
    "        )\n",
    "\n",
    "        clf.fit(train_db)\n",
    "\n",
    "        y_true = np.array([1.0 for _ in range(len(test_db.pos))] + [0.0 for _ in range(len(test_db.neg))])\n",
    "        y_pred = clf.predict_proba(test_db)\n",
    "        y_label = np.array([1.0 if i > 0.5 else 0.0 for i in y_pred])\n",
    "\n",
    "        results.setdefault('roc', []).append(roc_auc_score(y_true, y_pred))\n",
    "        results.setdefault('pr', []).append(pr_auc_score(y_true, y_pred))\n",
    "        results.setdefault('log_loss', []).append(log_loss(y_true, y_pred))\n",
    "        results.setdefault('precision', []).append(precision_score(y_true, y_label))\n",
    "        results.setdefault('recall', []).append(recall_score(y_true, y_label))\n",
    "    for key, value in results.items():\n",
    "        metrics.setdefault(key, []).append(np.mean(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc': [0.9337959183673469,\n",
       "  0.9804999999999999,\n",
       "  1.0,\n",
       "  0.9916437098255282,\n",
       "  0.891015625],\n",
       " 'pr': [0.9303855664365361,\n",
       "  0.9803909019089225,\n",
       "  1.0,\n",
       "  0.9919522567091352,\n",
       "  0.8699783790341066],\n",
       " 'log_loss': [0.3092268185953405,\n",
       "  0.2291802806775261,\n",
       "  0.21881786172520182,\n",
       "  0.20021028887455397,\n",
       "  0.3833369362392089],\n",
       " 'precision': [0.8468421052631581,\n",
       "  0.8635234330886504,\n",
       "  1.0,\n",
       "  0.9122689075630251,\n",
       "  0.7619047619047619],\n",
       " 'recall': [0.9485714285714286,\n",
       "  0.95,\n",
       "  0.888888888888889,\n",
       "  0.9454545454545455,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import NeuralRDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2179ef4430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "for fold in range(len(pos)):\n",
    "    results = {}\n",
    "    for _ in range(len(pos)):\n",
    "        test_db = Database()\n",
    "        test_db.pos = pos[fold]\n",
    "        test_db.neg = neg[fold]\n",
    "        test_db.facts = facts[fold]\n",
    "\n",
    "        train_db = Database()\n",
    "        for i in range(len(pos)):\n",
    "            if fold == i:\n",
    "                continue\n",
    "            train_db.pos.extend(pos[i])\n",
    "            train_db.neg.extend(neg[i])\n",
    "            train_db.facts.extend(facts[i])\n",
    "\n",
    "        bk = Background(\n",
    "            modes=modes,\n",
    "        )\n",
    "\n",
    "        clf = NeuralRDN(\n",
    "            background=bk,\n",
    "            target=\"advisedby\",\n",
    "            n_estimators=1,\n",
    "            n_boost_estimators=10,\n",
    "        )\n",
    "\n",
    "        clf.fit(train_db)\n",
    "\n",
    "        y_true = np.array([1.0 for _ in range(len(test_db.pos))] + [0.0 for _ in range(len(test_db.neg))])\n",
    "        y_pred = clf.predict_proba(test_db)\n",
    "        y_label = np.array([1.0 if i > 0.5 else 0.0 for i in y_pred])\n",
    "        \n",
    "        results.setdefault('roc', []).append(roc_auc_score(y_true, y_pred))\n",
    "        results.setdefault('pr', []).append(pr_auc_score(y_true, y_pred))\n",
    "        results.setdefault('log_loss', []).append(log_loss(y_true, y_pred))\n",
    "        results.setdefault('precision', []).append(precision_score(y_true, y_label))\n",
    "        results.setdefault('recall', []).append(recall_score(y_true, y_label))\n",
    "    for key, value in results.items():\n",
    "        metrics.setdefault(key, []).append(np.mean(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc': [0.9012244897959183,\n",
       "  0.9780000000000001,\n",
       "  1.0,\n",
       "  0.9934802571166207,\n",
       "  0.876953125],\n",
       " 'pr': [0.8687635544917756,\n",
       "  0.9786785789431922,\n",
       "  1.0000000000000002,\n",
       "  0.9936771893776373,\n",
       "  0.8442381193368036],\n",
       " 'log_loss': [0.34772562357730097,\n",
       "  0.20886873151175678,\n",
       "  0.15615490740941215,\n",
       "  0.14372346808174347,\n",
       "  0.5810681204486172],\n",
       " 'precision': [0.7966405075952199,\n",
       "  0.8899999999999999,\n",
       "  1.0,\n",
       "  0.9244727568446732,\n",
       "  0.7619047619047619],\n",
       " 'recall': [0.937142857142857,\n",
       "  0.95,\n",
       "  0.888888888888889,\n",
       "  0.9515151515151515,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for fold in range(len(pos)):\n",
    "    results = {}\n",
    "    for _ in range(len(pos)):\n",
    "        test_db = Database()\n",
    "        test_db.pos = pos[fold]\n",
    "        test_db.neg = neg[fold]\n",
    "        test_db.facts = facts[fold]\n",
    "\n",
    "        train_db = Database()\n",
    "        for i in range(len(pos)):\n",
    "            if fold == i:\n",
    "                continue\n",
    "            train_db.pos.extend(pos[i])\n",
    "            train_db.neg.extend(neg[i])\n",
    "            train_db.facts.extend(facts[i])\n",
    "\n",
    "        bk = Background(\n",
    "            modes=modes,\n",
    "        )\n",
    "\n",
    "        clf = NeuralRDN(\n",
    "            background=bk,\n",
    "            target=\"advisedby\",\n",
    "            n_estimators=10,\n",
    "            n_boost_estimators=1,\n",
    "        )\n",
    "\n",
    "        clf.fit(train_db)\n",
    "\n",
    "        y_true = np.array([1.0 for _ in range(len(test_db.pos))] + [0.0 for _ in range(len(test_db.neg))])\n",
    "        y_pred = clf.predict_proba(test_db)\n",
    "        y_label = np.array([1.0 if i > 0.5 else 0.0 for i in y_pred])\n",
    "        \n",
    "        results.setdefault('roc', []).append(roc_auc_score(y_true, y_pred))\n",
    "        results.setdefault('pr', []).append(pr_auc_score(y_true, y_pred))\n",
    "        results.setdefault('log_loss', []).append(log_loss(y_true, y_pred))\n",
    "        results.setdefault('precision', []).append(precision_score(y_true, y_label))\n",
    "        results.setdefault('recall', []).append(recall_score(y_true, y_label))\n",
    "    for key, value in results.items():\n",
    "        metrics.setdefault(key, []).append(np.mean(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc': [0.9517551020408164,\n",
       "  0.9735000000000001,\n",
       "  1.0,\n",
       "  0.9804407713498623,\n",
       "  0.901953125],\n",
       " 'pr': [0.956262796027502,\n",
       "  0.9733332551157208,\n",
       "  1.0000000000000002,\n",
       "  0.9833127997249527,\n",
       "  0.8918796992481204],\n",
       " 'log_loss': [0.24647344813016908,\n",
       "  0.18871770443511196,\n",
       "  0.18403350477003388,\n",
       "  0.17861312601828214,\n",
       "  0.486909983921214],\n",
       " 'precision': [0.85,\n",
       "  0.8658949745906268,\n",
       "  1.0,\n",
       "  0.9142857142857143,\n",
       "  0.7619047619047619],\n",
       " 'recall': [0.9714285714285713,\n",
       "  0.97,\n",
       "  0.8666666666666666,\n",
       "  0.9696969696969697,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnboost = {'roc': [0.9337959183673469,\n",
    "  0.9804999999999999,\n",
    "  1.0,\n",
    "  0.9916437098255282,\n",
    "  0.891015625],\n",
    " 'pr': [0.9303855664365361,\n",
    "  0.9803909019089225,\n",
    "  1.0,\n",
    "  0.9919522567091352,\n",
    "  0.8699783790341066],\n",
    " 'log_loss': [0.3092268185953405,\n",
    "  0.2291802806775261,\n",
    "  0.21881786172520182,\n",
    "  0.20021028887455397,\n",
    "  0.3833369362392089],\n",
    " 'precision': [0.8468421052631581,\n",
    "  0.8635234330886504,\n",
    "  1.0,\n",
    "  0.9122689075630251,\n",
    "  0.7619047619047619],\n",
    " 'recall': [0.9485714285714286,\n",
    "  0.95,\n",
    "  0.888888888888889,\n",
    "  0.9454545454545455,\n",
    "  1.0]}\n",
    "\n",
    "boostingrdnmlp = {'roc': [0.9012244897959183,\n",
    "  0.9780000000000001,\n",
    "  1.0,\n",
    "  0.9934802571166207,\n",
    "  0.876953125],\n",
    " 'pr': [0.8687635544917756,\n",
    "  0.9786785789431922,\n",
    "  1.0000000000000002,\n",
    "  0.9936771893776373,\n",
    "  0.8442381193368036],\n",
    " 'log_loss': [0.34772562357730097,\n",
    "  0.20886873151175678,\n",
    "  0.15615490740941215,\n",
    "  0.14372346808174347,\n",
    "  0.5810681204486172],\n",
    " 'precision': [0.7966405075952199,\n",
    "  0.8899999999999999,\n",
    "  1.0,\n",
    "  0.9244727568446732,\n",
    "  0.7619047619047619],\n",
    " 'recall': [0.937142857142857,\n",
    "  0.95,\n",
    "  0.888888888888889,\n",
    "  0.9515151515151515,\n",
    "  1.0]}\n",
    "\n",
    "baggingrdnmlp = {'roc': [0.9517551020408164,\n",
    "  0.9735000000000001,\n",
    "  1.0,\n",
    "  0.9804407713498623,\n",
    "  0.901953125],\n",
    " 'pr': [0.956262796027502,\n",
    "  0.9733332551157208,\n",
    "  1.0000000000000002,\n",
    "  0.9833127997249527,\n",
    "  0.8918796992481204],\n",
    " 'log_loss': [0.24647344813016908,\n",
    "  0.18871770443511196,\n",
    "  0.18403350477003388,\n",
    "  0.17861312601828214,\n",
    "  0.486909983921214],\n",
    " 'precision': [0.85,\n",
    "  0.8658949745906268,\n",
    "  1.0,\n",
    "  0.9142857142857143,\n",
    "  0.7619047619047619],\n",
    " 'recall': [0.9714285714285713,\n",
    "  0.97,\n",
    "  0.8666666666666666,\n",
    "  0.9696969696969697,\n",
    "  1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Results for roc"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RDNBoost</th>\n",
       "      <th>Boosting RDN+MLP</th>\n",
       "      <th>Bagging RDN+MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959 +/- 0.082</td>\n",
       "      <td>0.950 +/- 0.102</td>\n",
       "      <td>0.962 +/- 0.067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RDNBoost Boosting RDN+MLP  Bagging RDN+MLP\n",
       "0  0.959 +/- 0.082  0.950 +/- 0.102  0.962 +/- 0.067"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Results for pr"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RDNBoost</th>\n",
       "      <th>Boosting RDN+MLP</th>\n",
       "      <th>Bagging RDN+MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.955 +/- 0.097</td>\n",
       "      <td>0.937 +/- 0.133</td>\n",
       "      <td>0.961 +/- 0.075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RDNBoost Boosting RDN+MLP  Bagging RDN+MLP\n",
       "0  0.955 +/- 0.097  0.937 +/- 0.133  0.961 +/- 0.075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Results for log_loss"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RDNBoost</th>\n",
       "      <th>Boosting RDN+MLP</th>\n",
       "      <th>Bagging RDN+MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.268 +/- 0.137</td>\n",
       "      <td>0.288 +/- 0.327</td>\n",
       "      <td>0.257 +/- 0.235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RDNBoost Boosting RDN+MLP  Bagging RDN+MLP\n",
       "0  0.268 +/- 0.137  0.288 +/- 0.327  0.257 +/- 0.235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Results for precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RDNBoost</th>\n",
       "      <th>Boosting RDN+MLP</th>\n",
       "      <th>Bagging RDN+MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.877 +/- 0.157</td>\n",
       "      <td>0.875 +/- 0.173</td>\n",
       "      <td>0.878 +/- 0.156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RDNBoost Boosting RDN+MLP  Bagging RDN+MLP\n",
       "0  0.877 +/- 0.157  0.875 +/- 0.173  0.878 +/- 0.156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Results for recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RDNBoost</th>\n",
       "      <th>Boosting RDN+MLP</th>\n",
       "      <th>Bagging RDN+MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947 +/- 0.070</td>\n",
       "      <td>0.946 +/- 0.071</td>\n",
       "      <td>0.956 +/- 0.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RDNBoost Boosting RDN+MLP  Bagging RDN+MLP\n",
       "0  0.947 +/- 0.070  0.946 +/- 0.071  0.956 +/- 0.092"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "for metric, _ in rdnboost.items():\n",
    "    display(Markdown('# Results for ' + metric))\n",
    "    table = []\n",
    "    table.append([\n",
    "        '%.3f +/- %.3f' % (np.array(rdnboost[metric]).mean(), 2 * np.array(rdnboost[metric]).std()),\n",
    "        '%.3f +/- %.3f' % (np.array(boostingrdnmlp[metric]).mean(), 2 * np.array(boostingrdnmlp[metric]).std()),\n",
    "        '%.3f +/- %.3f' % (np.array(baggingrdnmlp[metric]).mean(), 2 * np.array(baggingrdnmlp[metric]).std()),\n",
    "    ])\n",
    "    display(pd.DataFrame(table, columns=['RDNBoost', 'Boosting RDN+MLP', 'Bagging RDN+MLP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
